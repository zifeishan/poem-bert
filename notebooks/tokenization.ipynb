{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from bert import optimization\n",
    "from bert import modeling\n",
    "from bert import tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_paths = {\n",
    "    \"rbtl3\": \"/Users/zifei/Downloads/chinese-bert/chinese_rbtl3_L-3_H-1024_A-16\",\n",
    "    \"rbt-ext\": \"/Users/zifei/Downloads/chinese-bert/chinese_roberta_wwm_ext_L-12_H-768_A-12\",\n",
    "}\n",
    "bert_dir = bert_paths[\"rbtl3\"]\n",
    "tokenizer = tokenization.FullTokenizer(bert_dir + \"/vocab.txt\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]',\n",
       " '魅',\n",
       " '魍',\n",
       " '[UNK]',\n",
       " '缱',\n",
       " '绻',\n",
       " '难',\n",
       " '眠',\n",
       " '[UNK]',\n",
       " '吁',\n",
       " '[UNK]',\n",
       " '危',\n",
       " '乎',\n",
       " '高',\n",
       " '哉']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('魑魅魍魉缱绻难眠噫吁嚱危乎高哉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p_sep = re.compile(r\"([，。？！；])\")\n",
    "\n",
    "def split_sentence(content):\n",
    "    parts = [s for s in re.split(p_sep, content) if s]\n",
    "    sents = []\n",
    "    for i in range((len(parts) + 1) // 2):\n",
    "        sent = \"\".join(parts[i*2:i*2+2])\n",
    "        sents.append(sent)\n",
    "    return sents\n",
    "    \n",
    "\n",
    "sid = 0\n",
    "with open(\"sents_all.tsv\", \"w\") as fout:\n",
    "    for line in open(\"poems_all.tsv\"):\n",
    "        parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        pid, dynasty, author, title, other_tags, content = parts\n",
    "        sents = split_sentence(content)\n",
    "        for s in sents:\n",
    "            sid += 1\n",
    "            print(\"\\t\".join([str(sid), str(pid), s]), file=fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split in module re:\n",
      "\n",
      "split(pattern, string, maxsplit=0, flags=0)\n",
      "    Split the source string by the occurrences of the pattern,\n",
      "    returning a list containing the resulting substrings.  If\n",
      "    capturing parentheses are used in pattern, then the text of all\n",
      "    groups in the pattern are also returned as part of the resulting\n",
      "    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n",
      "    and the remainder of the string is returned as the final element\n",
      "    of the list.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "help(re.split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
